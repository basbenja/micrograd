{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db40e48a",
   "metadata": {},
   "source": [
    "Veamos cómo hicimos algo similar a lo que se hace en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85c207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f371a6",
   "metadata": {},
   "source": [
    "Nosotros teníamos:\n",
    "```python\n",
    "    x1 = Value(2.0, label='x1')\n",
    "    x2 = Value(0.0, label='x2')\n",
    "    w1 = Value(-3.0, label='w1')\n",
    "    w2 = Value(1.0, label='w2')\n",
    "    b = Value(6.8813735870195432, label='b')\n",
    "    x1w1 = x1*w1; x1w1.label = 'x1*w1'\n",
    "    x2w2 = x2*w2; x2w2.label = 'x2*w2'\n",
    "    x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\n",
    "    n = x1w1x2w2 + b; n.label = 'n'\n",
    "    o = n.tanh(); o.label = 'o'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bda1ce",
   "metadata": {},
   "source": [
    "El análogo en PyTorch sería algo como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "#   - Casteamos a double porque es el tipo de datos que usa Python por defecto (es lo que\n",
    "#     pasa en Value); pero PyTorch por defecto usa float32.\n",
    "#   - En las hojas del grafo, tenemos que setear requires_grad en True porque por\n",
    "#     defecto es False por cuestiones de eficiencia\n",
    "x1 = torch.Tensor([2.0]).double();                  x1.requires_grad = True\n",
    "x2 = torch.Tensor([0.0]).double();                  x2.requires_grad = True\n",
    "w1 = torch.Tensor([-3.0]).double();                 w1.requires_grad = True\n",
    "w2 = torch.Tensor([1.0]).double();                  w2.requires_grad = True\n",
    "b  = torch.Tensor([6.8813735870195432]).double();   b.requires_grad  = True\n",
    "n = x1 * w1 + x2*w2 + b\n",
    "o = torch.tanh(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a76593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7071], dtype=torch.float64, grad_fn=<TanhBackward0>)\n",
      "0.7071066904050358\n"
     ]
    }
   ],
   "source": [
    "print(o)\n",
    "\n",
    "# .item() devuelve el elemento presente en un tensor que contiene solamente un valor\n",
    "print(o.data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eacd57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 -1.5000003851533106\n",
      "w1 1.0000002567688737\n",
      "x2 0.5000001283844369\n",
      "w2 0.5000001283844369\n"
     ]
    }
   ],
   "source": [
    "o.backward()\n",
    "\n",
    "print('x1', x1.grad.item())\n",
    "print('w1', w1.grad.item())\n",
    "print('x2', x2.grad.item())\n",
    "print('w2', x2.grad.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micrograd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
